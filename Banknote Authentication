import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler

def replace_none_with_zero(data):
  return [value if value is not None else 0 for value in data]

def get_report(y_true, y_pred, target_names=None):

    if None in y_true or None in y_pred:

        new_y_true = replace_none_with_zero(y_true)
        new_y_pred = replace_none_with_zero(y_pred)

        report = classification_report(new_y_true, new_y_pred, target_names=target_names)
    else:

        report = classification_report(y_true, y_pred, target_names=target_names)
    return report

data = pd.read_csv('/content/data_banknote_authentication.csv')

print('Number of Rows: ', data.shape[0])
print('Number of Columns: ', data.shape[1], '\n')
print('SubSet of Data:\n ', data.head(), '\n')

labels = ['Variance', 'Skewness', 'Kurtosis', 'Entropy', 'Target']
data.columns = labels
print('Columns Names:', data.columns, '\n')
print('Data Describe:\n ', data.describe(), '\n')
print('Data Information:'); print(data.info())

data.head()

print(data.duplicated().any())
duplicated = data.duplicated()
print('Number of duplicated data: ', duplicated[duplicated == True].size)

print('Correlation:')
print(data.corr()['Target'].sort_values(ascending=False))

Split data

x = data.drop('Target', axis=1).values
y = data['Target'].values
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)
print(X_train.shape)
print(y_train.shape)

#Model building

#with normal knn algorithm

import math

def euclidean_distance(point1, point2):
    distance = math.sqrt(sum([(a - b) ** 2 for a, b in zip(point1, point2)]))
    return distance

def manhattan_distance(point1, point2):
    distance = sum(abs(a - b) for a, b in zip(point1, point2))
    return distance



#Euclidean distance

import math

def euclidean_distance(point1, point2):
    distance = math.sqrt(sum([(a - b) ** 2 for a, b in zip(point1, point2)]))
    return distance

def k_nearest_neighbors(train_data, test_point, k):
    distances = [(euclidean_distance(train_point[0], test_point), train_point[1]) for train_point in train_data]
    distances.sort()  # Sort distances in ascending order
    nearest_neighbors = distances[:k]  # Select the k nearest neighbors
    return nearest_neighbors

def classify(test_point, train_data, k):
    nearest_neighbors = k_nearest_neighbors(train_data, test_point, k)
    votes = {}
    for distance, label in nearest_neighbors:
        votes[label] = votes.get(label, 0) + 1
    max_votes_label = max(votes, key=votes.get)
    return max_votes_label

train_data = list(zip(X_train, y_train))

y_pred = [classify(test_point, train_data, k=3) for test_point in X_test]

report = get_report(y_test, y_pred)
print(report)

#Manhattan distance


def k_nearest_neighbors(train_data, test_point, k):
    distances = [(manhattan_distance(train_point[0], test_point), train_point[1]) for train_point in train_data]
    distances.sort()  # Sort distances in ascending order
    nearest_neighbors = distances[:k]  # Select the k nearest neighbors
    return nearest_neighbors

def classify(test_point, train_data, k):
    nearest_neighbors = k_nearest_neighbors(train_data, test_point, k)
    votes = {}
    for distance, label in nearest_neighbors:
        votes[label] = votes.get(label, 0) + 1
    max_votes_label = max(votes, key=votes.get)
    return max_votes_label

train_data = list(zip(X_train, y_train))

y_pred = [classify(test_point, train_data, k=3) for test_point in X_test]

report = get_report(y_test, y_pred)
print(report)


#with a modified version of the k-Nearest Neighbors (KNN) algorithm that considers neighbors within a specified radius instead of a fixed number of neighbors (k)

#Euclidean distance

import math

def euclidean_distance(point1, point2):
    distance = math.sqrt(sum([(a - b) ** 2 for a, b in zip(point1, point2)]))
    return distance

def neighbors_within_radius(train_data, test_point, radius):
    neighbors = []
    for train_point, label in train_data:
        distance = euclidean_distance(train_point, test_point)
        if distance <= radius:
            neighbors.append((distance, label))
    return neighbors

def classify(test_point, train_data, radius):
    neighbors = neighbors_within_radius(train_data, test_point, radius)
    if not neighbors:
        return None
    votes = {}
    for distance, label in neighbors:
        votes[label] = votes.get(label, 0) + 1
    max_votes_label = max(votes, key=votes.get)
    return max_votes_label

train_data = list(zip(X_train, y_train))

y_pred = [classify(test_point, train_data, radius = 3) for test_point in X_test]

report = get_report(y_test, y_pred)
print(report)

#Manhattan distance


def neighbors_within_radius(train_data, test_point, radius):
    neighbors = []
    for train_point, label in train_data:
        distance = manhattan_distance(train_point, test_point)
        if distance <= radius:
            neighbors.append((distance, label))
    return neighbors

def classify(test_point, train_data, radius):
    neighbors = neighbors_within_radius(train_data, test_point, radius)
    if not neighbors:
        return None
    votes = {}
    for distance, label in neighbors:
        votes[label] = votes.get(label, 0) + 1
    max_votes_label = max(votes, key=votes.get)
    return max_votes_label

train_data = list(zip(X_train, y_train))

y_pred = [classify(test_point, train_data, radius = 3) for test_point in X_test]

report = get_report(y_test, y_pred)
print(report)
