import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler

def replace_none_with_zero(data):
  return [value if value is not None else 0 for value in data]

def get_report(y_true, y_pred, target_names=None):

    if None in y_true or None in y_pred:

        new_y_true = replace_none_with_zero(y_true)
        new_y_pred = replace_none_with_zero(y_pred)

        report = classification_report(new_y_true, new_y_pred, target_names=target_names)
    else:

        report = classification_report(y_true, y_pred, target_names=target_names)
    return report

data=pd.read_csv('/content/wine.csv',names=['Cultivars','Alcohol','Malic acid','Ash','Alcalinity of ash',
'Magnesium','Total Phenols','Flavanoids','Nonflavanoid phenols',
'Proanthocyanins','Color intensity','Hue','OD280/OD315 of diluted wines','Proline'])
print(data)
input=['Alcohol','Malic acid','Ash','Alcalinity of ash',
'Magnesium','Total Phenols','Flavanoids','Nonflavanoid phenols','Proanthocyanins','Color intensity','Hue','OD280/OD315 of diluted wines','Proline']
x=data[input]
y=data['Cultivars']

print(data.describe())
print(data.dtypes)
print(data.corr())

data.info()

#Split data and scale

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3 )

print(f"""SHAPES :
x_train : {x_train.shape}
y_train : {y_train.shape}
x_test : {x_test.shape}
y_test : {y_test.shape}""")

ss=StandardScaler()
ex=ss.fit_transform(x_train)
extest=ss.fit_transform(x_test)

#Model building

#with normal knn algorithm

#Euclidean distance

import math

def euclidean_distance(point1, point2):
    distance = math.sqrt(sum([(a - b) ** 2 for a, b in zip(point1, point2)]))
    return distance

def manhattan_distance(point1, point2):
    distance = sum(abs(a - b) for a, b in zip(point1, point2))
    return distance




def k_nearest_neighbors(train_data, test_point, k):
    distances = [(euclidean_distance(train_point[0], test_point), train_point[1]) for train_point in train_data]
    distances.sort()  # Sort distances in ascending order
    nearest_neighbors = distances[:k]  # Select the k nearest neighbors
    return nearest_neighbors

def classify(test_point, train_data, k):
    nearest_neighbors = k_nearest_neighbors(train_data, test_point, k)
    votes = {}
    for distance, label in nearest_neighbors:
        votes[label] = votes.get(label, 0) + 1
    max_votes_label = max(votes, key=votes.get)
    return max_votes_label

train_data = list(zip(ex, y_train))

y_pred = [classify(test_point, train_data, k=5) for test_point in extest]

report = get_report(y_test, y_pred)
print(report)

#Manhattan distance


def k_nearest_neighbors(train_data, test_point, k):
    distances = [(manhattan_distance(train_point[0], test_point), train_point[1]) for train_point in train_data]
    distances.sort()  # Sort distances in ascending order
    nearest_neighbors = distances[:k]  # Select the k nearest neighbors
    return nearest_neighbors

def classify(test_point, train_data, k):
    nearest_neighbors = k_nearest_neighbors(train_data, test_point, k)
    votes = {}
    for distance, label in nearest_neighbors:
        votes[label] = votes.get(label, 0) + 1
    max_votes_label = max(votes, key=votes.get)
    return max_votes_label

train_data = list(zip(ex, y_train))

y_pred = [classify(test_point, train_data, k=5) for test_point in extest]

report = get_report(y_test, y_pred)
print(report)

#with a modified version of the k-Nearest Neighbors (KNN) algorithm that considers neighbors within a specified radius instead of a fixed number of neighbors (k)

#Euclidean distance


def neighbors_within_radius(train_data, test_point, radius):
    neighbors = []
    for train_point, label in train_data:
        distance = euclidean_distance(train_point, test_point)
        if distance <= radius:
            neighbors.append((distance, label))
    return neighbors

def classify(test_point, train_data, radius):
    neighbors = neighbors_within_radius(train_data, test_point, radius)
    if not neighbors:
        return None
    votes = {}
    for distance, label in neighbors:
        votes[label] = votes.get(label, 0) + 1
    max_votes_label = max(votes, key=votes.get)
    return max_votes_label

train_data = list(zip(ex, y_train))

y_pred = [classify(test_point, train_data, radius = 3) for test_point in extest]

report = get_report(y_test, y_pred)
print(report)

#Manhattan distance


def neighbors_within_radius(train_data, test_point, radius):
    neighbors = []
    for train_point, label in train_data:
        distance = manhattan_distance(train_point, test_point)
        if distance <= radius:
            neighbors.append((distance, label))
    return neighbors

def classify(test_point, train_data, radius):
    neighbors = neighbors_within_radius(train_data, test_point, radius)
    if not neighbors:
        return None
    votes = {}
    for distance, label in neighbors:
        votes[label] = votes.get(label, 0) + 1
    max_votes_label = max(votes, key=votes.get)
    return max_votes_label

train_data = list(zip(ex, y_train))

y_pred = [classify(test_point, train_data, radius = 3) for test_point in extest]

report = get_report(y_test, y_pred)
print(report)
